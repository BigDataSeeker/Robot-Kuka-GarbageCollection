{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjZufUL6gnw2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "from math import cos,sin\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "h = 0.7\n",
        "alpha = math.radians(45)\n",
        "f_l = 26\n",
        "x0 = 0.072\n",
        "y0 = 0.96\n",
        "'''\n",
        "h11 = f_l\n",
        "h12 = x0*cos(alpha)\n",
        "h13 = x0*h*cos(alpha)\n",
        "h21 = 0\n",
        "h22 = f_l*sin(alpha)+y0*cos(alpha)\n",
        "h23 = y0*h*cos(alpha)-f_l*h*sin(alpha)\n",
        "h31 = 0\n",
        "h32 = cos(alpha)\n",
        "h33 = h*cos(alpha)'''\n",
        "\n",
        "h11 = 1\n",
        "h12 = 0\n",
        "h13 = 0\n",
        "h21 = 0\n",
        "h22 = sin(alpha)\n",
        "h23 = -h*sin(alpha)\n",
        "h31 = 0\n",
        "h32 = cos(alpha)\n",
        "h33 = h*cos(alpha)\n",
        "\n",
        "pts_src = np.array([[296,0],[753,0],[1160,1920],[19,1920]])\n",
        "\n",
        "pts_dst = np.array([[296,0],[753,0],[950,1920],[490,1920]])\n",
        "\n",
        "h_m, status = cv2.findHomography(pts_src, pts_dst)\n",
        "\n",
        "inv_h_matrix = np.array([[h11,h12,h13],[h21,h22,h23],[h31,h32,h33]])\n",
        "print(inv_h_matrix)\n",
        "h_matrix = np.linalg.inv(inv_h_matrix)\n",
        "print(h_matrix)\n",
        "mat_mul = np.matmul(inv_h_matrix,h_matrix)\n",
        "print(mat_mul)\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/GarbageClassifier/object2transform_homograpfy.jpg')\n",
        "cv2_imshow(img)\n",
        "\n",
        "im_out = cv2.warpPerspective(img, h_m, (img.shape[1],1300))\n",
        "cv2_imshow(im_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykIZ7kOokUNO",
        "outputId": "b868208f-173f-467e-91e1-6686a521a0a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1737.4216529098514"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.sqrt(535**2 + 1653**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qpr637M-x4L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99660d5f-d4c9-455a-a60e-c0898132b83d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "from math import cos,sin,tan,sqrt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# the class warps input frame perspective to overhead view and calculates relative to robot coordinates of the given within frame objects\n",
        "class camera():\n",
        "  def __init__(self,hor_fov,ver_fov,height = None,tilt_a = None):\n",
        "    self.hor_fov = hor_fov\n",
        "    self.ver_fov = ver_fov\n",
        "    self.h = height\n",
        "    self.tilt_a = tilt_a\n",
        "    self.d_f =None\n",
        "    self.d_r =None\n",
        "    self.w_f =None\n",
        "    self.w_r =None\n",
        "    self.area_of_view_size = [None,None]\n",
        "    self.area_of_view_pxl_size = [None,None]\n",
        "    self.aov_object_coords = None # relative to robot\n",
        "\n",
        "  def rectify_perspective(self,img,h = None,tilt_a = None,detections = []):\n",
        "    if h is not None:\n",
        "      self.h = h\n",
        "    if tilt_a is not None:\n",
        "      self.tilt_a = tilt_a\n",
        "    if img is None:\n",
        "      print('Given images is None')\n",
        "      return\n",
        "    self.d_f = self.h*tan(self.tilt_a - self.ver_fov)\n",
        "    self.d_r = self.h*tan(self.tilt_a + self.ver_fov)\n",
        "    self.area_of_view_size[1] = self.d_r - self.d_f\n",
        "\n",
        "    self.w_f = sqrt(self.d_f**2+self.h**2)*tan(self.hor_fov)\n",
        "    self.w_r = sqrt(self.d_r**2+self.h**2)*tan(self.hor_fov)\n",
        "    self.area_of_view_size[0] = 2*self.w_r\n",
        "    w_f_pxl = int((self.w_f/self.w_r)*img.shape[1])\n",
        "    self.area_of_view_pxl_size[0] = img.shape[1]\n",
        "    self.area_of_view_pxl_size[1] = int(img.shape[1]*self.area_of_view_size[1]/self.area_of_view_size[0])\n",
        "\n",
        "\n",
        "    pts_src = np.array([[0,0],[img.shape[1],0],[img.shape[1],img.shape[0]],[0,img.shape[0]]])\n",
        "    pts_dst = np.array([[0,0],[self.area_of_view_pxl_size[0],0],[int((self.area_of_view_pxl_size[0]+w_f_pxl)/2),self.area_of_view_pxl_size[1]],[int((self.area_of_view_pxl_size[0]-w_f_pxl)/2),self.area_of_view_pxl_size[1]]])\n",
        "    h_m, status = cv2.findHomography(pts_src, pts_dst)\n",
        "    rectified_img = cv2.warpPerspective(img, h_m, (self.area_of_view_pxl_size[0],self.area_of_view_pxl_size[1]))\n",
        "    self.aov_object_coords = []\n",
        "    if len(detections) != 0:\n",
        "      for det in detections:\n",
        "        x11,y11,x22,y22 = det[0],det[1],det[2],det[3]\n",
        "        x_c = int((x11+x22)/2)\n",
        "        y_c = int((y11+y22)/2)\n",
        "        frame_coords_pxl = np.array([[x_c],[y_c],[1]])\n",
        "        aov_object_coords_pxl = np.matmul(h_m,frame_coords_pxl)\n",
        "        y_o = float(self.area_of_view_size[1]*(1 - aov_object_coords_pxl[1]/self.area_of_view_pxl_size[1])+self.d_f)\n",
        "        x_o = float(self.area_of_view_size[0]*aov_object_coords_pxl[0]/self.area_of_view_pxl_size[0] - self.w_r)\n",
        "        self.aov_object_coords.append([x_o,y_o])\n",
        "    return rectified_img,self.aov_object_coords\n",
        "\n",
        "\n",
        "  def draw_object_map(self,plot = False):\n",
        "    # the method plots the objects map of space before robot\n",
        "    object_pxl_map = np.ones((int(self.area_of_view_pxl_size[1]*(1+self.d_f/self.area_of_view_size[1])),self.area_of_view_pxl_size[0],3))*150\n",
        "    x_r_coords = []\n",
        "    y_r_coords = []\n",
        "    for obj in self.aov_object_coords:\n",
        "      x_r = obj[0]\n",
        "      x_r_coords.append(x_r)\n",
        "      y_r = obj[1]\n",
        "      y_r_coords.append(y_r)\n",
        "      x_pxl = int(self.area_of_view_pxl_size[0]*(x_r+self.w_r)/self.area_of_view_size[0])\n",
        "      y_pxl = int(self.area_of_view_pxl_size[1]*(1 - (y_r-self.d_f)/self.area_of_view_size[1]))\n",
        "      object_pxl_map = cv2.circle(object_pxl_map, (x_pxl,y_pxl), radius=10, color=(100, 0, 200), thickness=10)\n",
        "    if plot and x_r_coords and y_r_coords:\n",
        "      ax = plt.gca()\n",
        "      ax.spines['top'].set_color('none')\n",
        "      ax.spines['left'].set_position('zero')\n",
        "      ax.spines['right'].set_color('none')\n",
        "      ax.spines['bottom'].set_position('zero')\n",
        "\n",
        "      plt.xlim(-self.w_r,self.w_r)\n",
        "      plt.ylim(0,self.d_r)\n",
        "      plt.scatter(x_r_coords, y_r_coords)\n",
        "      plt.grid(True)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    return object_pxl_map\n",
        "\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/GarbageClassifier/TACO/test_imgs_my_in/2objects_to_trnaform.jpg')\n",
        "#cv2_imshow(img)\n",
        "\n",
        "iph4 = camera(math.radians(30.41),math.radians(23.75))\n",
        "img_rectified,obj_coords = iph4.rectify_perspective(img,0.5,math.radians(45),[[679,216,900,393]])\n",
        "cv2_imshow(img_rectified)\n",
        "\n",
        "cv2_imshow(iph4.draw_object_map(plot = True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(iph4.d_f,iph4.d_r,iph4.w_f,iph4.w_r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcqP7MO2HZhV",
        "outputId": "fb9445b8-ab6a-46d8-aaed-c914acbe68ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1898923261425237 1.1632908211056585 0.2809855379810598 0.6954636110570259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "!pip install -U -r yolov5/requirements.txt  # install dependencies\n",
        "%cd /content/yolov5"
      ],
      "metadata": {
        "id": "yyFKtOEJL636"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import sys\n",
        "sys.path.append('/content/yolov5')\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.augmentations import  letterbox\n",
        "from utils.general import non_max_suppression,scale_coords\n",
        "\n",
        "class camera():\n",
        "  def __init__(self,hor_fov,ver_fov,height = None,tilt_a = None):\n",
        "    self.hor_fov = hor_fov\n",
        "    self.ver_fov = ver_fov\n",
        "    self.h = height\n",
        "    self.tilt_a = tilt_a\n",
        "    self.d_f =None\n",
        "    self.d_r =None\n",
        "    self.w_f =None\n",
        "    self.w_r =None\n",
        "    self.area_of_view_size = [None,None]\n",
        "    self.area_of_view_pxl_size = [None,None]\n",
        "    self.aov_object_coords = None # relative to robot\n",
        "\n",
        "  def rectify_perspective(self,img,h = None,tilt_a = None,detections = []):\n",
        "    if h is not None:\n",
        "      self.h = h\n",
        "    if tilt_a is not None:\n",
        "      self.tilt_a = tilt_a\n",
        "    if img is None:\n",
        "      print('Given images is None')\n",
        "      return\n",
        "    self.d_f = self.h*tan(self.tilt_a - self.ver_fov)\n",
        "    self.d_r = self.h*tan(self.tilt_a + self.ver_fov)\n",
        "    self.area_of_view_size[1] = self.d_r - self.d_f\n",
        "\n",
        "    self.w_f = sqrt(self.d_f**2+self.h**2)*tan(self.hor_fov)\n",
        "    self.w_r = sqrt(self.d_r**2+self.h**2)*tan(self.hor_fov)\n",
        "    self.area_of_view_size[0] = 2*self.w_r\n",
        "    w_f_pxl = int((self.w_f/self.w_r)*img.shape[1])\n",
        "    self.area_of_view_pxl_size[0] = img.shape[1]\n",
        "    self.area_of_view_pxl_size[1] = int(img.shape[1]*self.area_of_view_size[1]/self.area_of_view_size[0])\n",
        "\n",
        "\n",
        "    pts_src = np.array([[0,0],[img.shape[1],0],[img.shape[1],img.shape[0]],[0,img.shape[0]]])\n",
        "    pts_dst = np.array([[0,0],[self.area_of_view_pxl_size[0],0],[int((self.area_of_view_pxl_size[0]+w_f_pxl)/2),self.area_of_view_pxl_size[1]],[int((self.area_of_view_pxl_size[0]-w_f_pxl)/2),self.area_of_view_pxl_size[1]]])\n",
        "    h_m, status = cv2.findHomography(pts_src, pts_dst)\n",
        "    rectified_img = cv2.warpPerspective(img, h_m, (self.area_of_view_pxl_size[0],self.area_of_view_pxl_size[1]))\n",
        "    self.aov_object_coords = []\n",
        "    if len(detections) != 0:\n",
        "      for det in detections:\n",
        "        x11,y11,x22,y22 = det[0],det[1],det[2],det[3]\n",
        "        x_c = int((x11+x22)/2)\n",
        "        y_c = int((y11+y22)/2)\n",
        "        frame_coords_pxl = np.array([[x_c],[y_c],[1]])\n",
        "        aov_object_coords_pxl = np.matmul(h_m,frame_coords_pxl)\n",
        "        y_o = float(self.area_of_view_size[1]*(1 - aov_object_coords_pxl[1]/self.area_of_view_pxl_size[1])+self.d_f)\n",
        "        x_o = float(self.area_of_view_size[0]*aov_object_coords_pxl[0]/self.area_of_view_pxl_size[0] - self.w_r)\n",
        "        self.aov_object_coords.append([x_o,y_o])\n",
        "    return rectified_img,self.aov_object_coords\n",
        "\n",
        "\n",
        "  def draw_object_map(self,plot = False):\n",
        "    # the method plots the objects map of space before robot\n",
        "    object_pxl_map = np.ones((int(self.area_of_view_pxl_size[1]*(1+self.d_f/self.area_of_view_size[1])),self.area_of_view_pxl_size[0],3))*150\n",
        "    x_r_coords = []\n",
        "    y_r_coords = []\n",
        "\n",
        "    for obj in self.aov_object_coords:\n",
        "      x_r = obj[0]\n",
        "      x_r_coords.append(x_r)\n",
        "      y_r = obj[1]\n",
        "      y_r_coords.append(y_r)\n",
        "      x_pxl = int(self.area_of_view_pxl_size[0]*(x_r+self.w_r)/self.area_of_view_size[0])\n",
        "      y_pxl = int(self.area_of_view_pxl_size[1]*(1 - (y_r-self.d_f)/self.area_of_view_size[1]))\n",
        "      object_pxl_map = cv2.circle(object_pxl_map, (x_pxl,y_pxl), radius=10, color=(100, 0, 200), thickness=10)\n",
        "    if plot and x_r_coords and y_r_coords:\n",
        "      ax = plt.gca()\n",
        "      ax.spines['top'].set_color('none')\n",
        "      ax.spines['left'].set_position('zero')\n",
        "      ax.spines['right'].set_color('none')\n",
        "      ax.spines['bottom'].set_position('zero')\n",
        "\n",
        "      plt.xlim(-self.w_r,self.w_r)\n",
        "      plt.ylim(0,self.d_r)\n",
        "      plt.scatter(x_r_coords, y_r_coords)\n",
        "      plt.grid(True)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    return object_pxl_map\n",
        "\n",
        "def detect_sheet(model,weights,conf_thres,path2img,path2save,camera_class,device):\n",
        "  device = torch.device(device)\n",
        "  class_mapping = {0:'glass',1:'metal',2:'paper',3:'plastic'}\n",
        "  img = cv2.imread(path2img)\n",
        "  if img is not None:\n",
        "\n",
        "    img2feed = letterbox(img.copy(), (640,640), stride=32, auto=True)[0]\n",
        "    img2feed = img2feed.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img2feed = np.ascontiguousarray(img2feed)\n",
        "    img2feed = torch.from_numpy(img2feed).to(device)\n",
        "    img2feed = img2feed.float()\n",
        "    img2feed /= 255\n",
        "    img2feed = img2feed[None]\n",
        "\n",
        "    pred = model(img2feed, augment=False, visualize=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres = conf_thres, iou_thres = 0.5, classes = None, agnostic = False, max_det=1000)\n",
        "    i = 1\n",
        "\n",
        "    for idx in range(len(pred)):\n",
        "      pred[idx][:, :4] = scale_coords(img2feed.shape[2:], pred[idx][:, :4], img.shape).round()\n",
        "    #print(pred)\n",
        "      img_rectified,obj_coords = camera_class.rectify_perspective(img,0.7,math.radians(20),reversed(pred[idx]))\n",
        "\n",
        "\n",
        "      for *xyxy, conf, cls in reversed(pred[idx]):\n",
        "        i += 1\n",
        "        xyxy = [int(c.tolist()) for c in xyxy]\n",
        "        t_l,b_r = (xyxy[0],xyxy[1]),(xyxy[2],xyxy[3])\n",
        "        t_r = (b_r[0],t_l[1])\n",
        "        b_l = (t_l[0],b_r[1])\n",
        "        points = np.array([t_l,t_r,b_r,b_l])\n",
        "\n",
        "        cv2.polylines(img,pts = [points],isClosed = True, color = (0, 200, 100), thickness = 4)\n",
        "        img = cv2.putText(img, class_mapping[cls.item()-i]+':'+str(round(conf.item(),2)), t_l, cv2.FONT_HERSHEY_SIMPLEX,3, (255, 0, 0), 5, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "    cv2_imshow(img)\n",
        "    cv2_imshow(img_rectified)\n",
        "    camera_class.draw_object_map(True)\n",
        "\n",
        "\n",
        "shown = 0\n",
        "s_dir = '/content/drive/MyDrive/GarbageClassifier/TACO/test_imgs_my_in'\n",
        "\n",
        "d_dir = '/content/drive/MyDrive/GarbageClassifier/TACO/test_imgs_my_out'\n",
        "\n",
        "weights = '/content/drive/MyDrive/GarbageClassifier/TACO/yolo_taco/best_100epochs.pt'\n",
        "device = 'cpu'\n",
        "\n",
        "model = DetectMultiBackend(weights, device=device, dnn=False, data='/content/yolov5/data/coco128.yaml')\n",
        "\n",
        "iph4 = camera(math.radians(30.41),math.radians(23.75))\n",
        "\n",
        "for img_name in ['/content/drive/MyDrive/GarbageClassifier/TACO/test_imgs_my_in/2objects_to_trnaform_h0.5.jpg','/content/drive/MyDrive/GarbageClassifier/TACO/test_imgs_my_in/metal_glass_objects2detect.jpg']:\n",
        "\n",
        "  detect_sheet(model,weights,conf_thres = 0.1,\n",
        "               path2img = os.path.join(dir,img_name),path2save = os.path.join(d_dir,img_name),camera_class = iph4, device = device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fi9ctcYQVn3C",
        "outputId": "8b7b1373-a2a8-417e-8413-fc68aa7c1eb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MfAUGh8rXn16"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}